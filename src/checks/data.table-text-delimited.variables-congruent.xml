<?xml version="1.0" encoding="UTF-8"?>
<mdq:check xmlns:mdq="https://nceas.ucsb.edu/mdqe/v1"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="https://nceas.ucsb.edu/mdqe/v1 ../schemas/schema1.xsd">
  <id>data.table-text-delimited.variables-congruent</id>
  <name>Text delimited table variables names congruent</name>
  <description>Variable (column) names in a file should be congruent with attributes in the file's metadata.</description>
  <type>Interoperable</type>
  <level>REQUIRED</level>
  <environment>python</environment>
  <code><![CDATA[

def call():
    global output
    global status
    global output_identifiers
    global output_type
    global metadigpy_result

    from metadig import StoreManager
    from metadig import metadata as md
    import pandas as pd
    import io
    import gc
    import numpy as np

    manager = StoreManager(storeConfiguration)  

    output_data = []
    status_data = []
    output_identifiers = []
    output_type = []
    metadigpy_result = {}

    if not dataPids or len(dataPids) == 0:
      output_data = "No data objects found."
      output_type = "text"

    for pid in dataPids:
        output_identifiers.append(pid)

        # If data object is not available, skip the pid.
        try:
            # if file is not text/csv, skip it
            # otherwise get the object and filename
            obj, fname, csv_status = md.get_valid_csv(manager, pid)
            if csv_status == "SKIP":
                output_data.append(f"`{fname}` is not a text-delimited table, skipping.")
                output_type.append("markdown")
                status_data.append(csv_status)
                continue
        except Exception as e:
            output_data.append(f"Unexpected Exception: {e}")
            output_type.append("text")
            status_data.append("ERROR")
            continue

        # Ensure that the data object is documented in the list of entity names
        entity_index = md.find_entity_index(fname, pid, entityNames, ids)
        if entity_index is None:
            output_data.append(f"`{fname}` does not appear to be documented in the metadata.")
            output_type.append("markdown")
            status_data.append("FAILURE")
            continue

        # Set the default expecated header line value (the first row is headers)
        num_header_lines = 0
        # headerLines represents 'numHeaderLines' which is retrieved from the EML document
        if isinstance(headerLines, list):
            # If we successfully retrieve a list, we will check what the value is
            header_line_value = headerLines[entity_index]
            if header_line_value is None or str(header_line_value).lower() == 'null':
                # No header lines specified
                pass
            elif isinstance(header_line_value, (int, float)):
                # convert float to int
                num_header_lines = int(header_line_value)
            else:
                # try to parse numeric strings
                try:
                    num_header_lines = int(float(header_line_value))
                except (ValueError, TypeError):
                    pass
        else:
            try:
                num_header_lines = int(float(headerLines))
            except (ValueError, TypeError):
                pass
        
        # Read the data object
        obj_bytes_read = obj.read()
        encoding_type, enc_msg = md.detect_text_encoding(obj_bytes_read)
        d_read_decoded = obj_bytes_read.decode(encoding_type)
        df, error = md.read_csv_with_metadata(d_read_decoded, fieldDelimiter[entity_index], num_header_lines, encoding_type, dtype_string = True)
        if error:
            output_data.append(f"`{fname}` is unable to be read as a table: {error}.")
            output_type.append("markdown")
            status_data.append("FAILURE")
            continue

        # cleanup
        del obj_bytes_read

        # Extract the entity from the metadata doc and attributeNames
        ent = md.find_eml_entity(document, pid, fname)
        att_names = [elem.text for elem in ent.findall(".//attributeName")]
        col_names = list(df.columns)
        if len(att_names) == 0:
            output_data.append(f"Cannot find attribute names.")
            output_type.append("markdown")
            status_data.append("FAILURE")
            continue
        if len(col_names) == 0:
            output_data.append(f"Cannot find column names.")
            output_type.append("markdown")
            status_data.append("FAILURE")
            continue
        # Check if column names match documentation
        if att_names == col_names:
            output_data.append(f"`{fname}` variable names match documentation.")
            output_type.append("markdown")
            status_data.append("SUCCESS")
        else:
            # Create a table to assist with comparing the variable names
            max_len = max(len(att_names), len(col_names))
            att_names_padded = att_names + ["NULL"] * (max_len - len(att_names))
            col_names_padded = col_names + ["NULL"] * (max_len - len(col_names))

            data = {'att_names': att_names_padded, 'col_names': col_names_padded}
            df = pd.DataFrame(data)
            filtered_df = df[df['att_names'] != df['col_names']]
            # get filtered attribute and column names to only show mismatched attributes
            att_names = filtered_df.get('att_names').tolist()
            col_names = filtered_df.get('col_names').tolist()
            # Get the max width so that we can insert the correct amount of spaces between pipes
            att_name_mxw = max(
                len("Attribute Names (Expected)"),
                max(len(str(a)) for a in att_names)
            )
            col_name_mxw = max(
                len("Variable Names (CSV)"),
                max(len(str(c)) for c in col_names)
            )
            header = f"| {'Attribute Names (Expected)':<{att_name_mxw}} | {'Variable Names (CSV)':<{col_name_mxw}} |"
            separator = f"|{'-' * (att_name_mxw + 2)}|{'-' * (col_name_mxw + 2)}|"
            att_names_quoted = [f'"{a}"' if a is not None else '"NULL"' for a in att_names]
            col_names_quoted = [f'"{c}"' if c is not None else '"NULL"' for c in col_names]
            # Create the rows
            rows = [
                f"| {md.escape_for_markdown(att):<{att_name_mxw}} | {md.escape_for_markdown(col):<{col_name_mxw}} |"
                for att, col in zip(att_names_quoted, col_names_quoted)
            ]
            row_list = [header, separator] + rows
            table_rows = "\n".join(row_list)
            output_data.append(f"`{fname}` variable names do not match documentation.\n{table_rows}")
            output_type.append("markdown")
            status_data.append("FAILURE")

        # cleanup
        del df
        gc.collect()

    successes = sum(x == "SUCCESS" for x in status_data)
    failures = sum(x == "FAILURE" for x in status_data)
    skips = sum(x == "SKIP" for x in status_data)
    errors = sum(x == "ERROR" for x in status_data)
    output = output_data
    
    if failures > 0:
        status = "FAILURE"
    elif all(s == "SKIP" for s in status_data):
        status = "SKIP"
    elif all(s == "ERROR" for s in status_data):
        status = "ERROR"
    else:
        status = "SUCCESS"

    metadigpy_result["identifiers"] = output_identifiers
    metadigpy_result["output"] = output_data
    metadigpy_result["status"] = status
    return True

  ]]></code>
  <selector>
    <name>entityNames</name>
    <xpath>/eml/dataset/*[self::dataTable|self::otherEntity]</xpath>
    <subSelector>
      <name>...</name>
      <xpath>./entityName</xpath>
    </subSelector>
  </selector>
  <selector>
    <name>objectNames</name>
    <xpath>/eml/dataset/*[self::dataTable|self::otherEntity]</xpath>
    <subSelector>
      <name>...</name>
      <xpath>./physical/objectName</xpath>
    </subSelector>
  </selector>
  <selector>
    <name>ids</name>
    <xpath>/eml/dataset/*[self::dataTable|self::otherEntity]/@id</xpath>
  </selector>
  <selector>
     <name>fieldDelimiter</name>
    <xpath>/eml/dataset/*[self::dataTable|self::otherEntity]</xpath>
     <subSelector>
        <name>...</name>
        <xpath>./physical/dataFormat/textFormat/simpleDelimited/fieldDelimiter</xpath>
    </subSelector>
  </selector>
  <selector>
     <name>headerLines</name>
    <xpath>/eml/dataset/*[self::dataTable|self::otherEntity]</xpath>
     <subSelector>
        <name>...</name>
        <xpath>./physical/dataFormat/textFormat/numHeaderLines</xpath>
    </subSelector>
  </selector>
  <dialect>
    <name>Ecological Metadata Language</name>
    <xpath>boolean(/*[local-name() = 'eml'])</xpath>
  </dialect>
</mdq:check>
